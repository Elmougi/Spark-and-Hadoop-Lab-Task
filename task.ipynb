{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abd2a088",
   "metadata": {},
   "source": [
    "1. Read the CSV file provided into a Spark DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b9560b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|gender| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\"/data/titanic.csv\", header=True, inferSchema=True)\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3a7f96",
   "metadata": {},
   "source": [
    "2. Count the number of males and females who had their Cabin as null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9d5f124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|gender|count|\n",
      "+------+-----+\n",
      "|female|  217|\n",
      "|  male|  470|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "filtered_data = df.filter(col('Cabin').isNull())\n",
    "grouping = filtered_data.groupBy(df.gender).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94b2f74",
   "metadata": {},
   "source": [
    "3. Find the average ages of passengers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "790feb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "average_age = df.select(avg('Age')).collect()[0][0]\n",
    "average_age = round(average_age , 0)\n",
    "print(average_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b483a1",
   "metadata": {},
   "source": [
    "4. Fill in the missing age values with this average value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "693516cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data before filling null values in age column:\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+---------------+--------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|gender| Age|SibSp|Parch|         Ticket|    Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+---------------+--------+-----+--------+\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|NULL|    0|    0|         330877|  8.4583| NULL|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|NULL|    0|    0|         244373|    13.0| NULL|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|NULL|    0|    0|           2649|   7.225| NULL|       C|\n",
      "|         27|       0|     3|Emir, Mr. Farred ...|  male|NULL|    0|    0|           2631|   7.225| NULL|       C|\n",
      "|         29|       1|     3|\"O'Dwyer, Miss. E...|female|NULL|    0|    0|         330959|  7.8792| NULL|       Q|\n",
      "|         30|       0|     3| Todoroff, Mr. Lalio|  male|NULL|    0|    0|         349216|  7.8958| NULL|       S|\n",
      "|         32|       1|     1|Spencer, Mrs. Wil...|female|NULL|    1|    0|       PC 17569|146.5208|  B78|       C|\n",
      "|         33|       1|     3|Glynn, Miss. Mary...|female|NULL|    0|    0|         335677|    7.75| NULL|       Q|\n",
      "|         37|       1|     3|    Mamee, Mr. Hanna|  male|NULL|    0|    0|           2677|  7.2292| NULL|       C|\n",
      "|         43|       0|     3| Kraeff, Mr. Theodor|  male|NULL|    0|    0|         349253|  7.8958| NULL|       C|\n",
      "|         46|       0|     3|Rogers, Mr. Willi...|  male|NULL|    0|    0|S.C./A.4. 23567|    8.05| NULL|       S|\n",
      "|         47|       0|     3|   Lennon, Mr. Denis|  male|NULL|    1|    0|         370371|    15.5| NULL|       Q|\n",
      "|         48|       1|     3|O'Driscoll, Miss....|female|NULL|    0|    0|          14311|    7.75| NULL|       Q|\n",
      "|         49|       0|     3| Samaan, Mr. Youssef|  male|NULL|    2|    0|           2662| 21.6792| NULL|       C|\n",
      "|         56|       1|     1|   Woolner, Mr. Hugh|  male|NULL|    0|    0|          19947|    35.5|  C52|       S|\n",
      "|         65|       0|     1|Stewart, Mr. Albe...|  male|NULL|    0|    0|       PC 17605| 27.7208| NULL|       C|\n",
      "|         66|       1|     3|Moubarek, Master....|  male|NULL|    1|    1|           2661| 15.2458| NULL|       C|\n",
      "|         77|       0|     3|   Staneff, Mr. Ivan|  male|NULL|    0|    0|         349208|  7.8958| NULL|       S|\n",
      "|         78|       0|     3|Moutal, Mr. Raham...|  male|NULL|    0|    0|         374746|    8.05| NULL|       S|\n",
      "|         83|       1|     3|McDermott, Miss. ...|female|NULL|    0|    0|         330932|  7.7875| NULL|       Q|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+---------------+--------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filled = df.fillna(average_age, subset=['Age'])\n",
    "print('data before filling null values in age column:')\n",
    "df.select(col('Age')).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f878fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data after filling null values in age column:\n",
      "+----+\n",
      "| Age|\n",
      "+----+\n",
      "|22.0|\n",
      "|38.0|\n",
      "|26.0|\n",
      "|35.0|\n",
      "|35.0|\n",
      "|30.0|\n",
      "|54.0|\n",
      "| 2.0|\n",
      "|27.0|\n",
      "|14.0|\n",
      "| 4.0|\n",
      "|58.0|\n",
      "|20.0|\n",
      "|39.0|\n",
      "|14.0|\n",
      "|55.0|\n",
      "| 2.0|\n",
      "|30.0|\n",
      "|31.0|\n",
      "|30.0|\n",
      "+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('data after filling null values in age column:')\n",
    "df_filled.select(col('Age')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266bdd00",
   "metadata": {},
   "source": [
    "5.Save the output to a CSV file in HDFS (depi_folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4e91100",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled.write.mode(\"overwrite\").csv(\"/data/titanic_filled.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1790053f",
   "metadata": {},
   "source": [
    "6. Count the total number of passengers who survived and those who did not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "57632340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Survived|count|\n",
      "+--------+-----+\n",
      "|  3ayesh|  342|\n",
      "| dead :(|  549|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "df_filled.groupBy('Survived').count().withColumn('Survived', when(col('Survived') == 1, '3ayesh').otherwise('dead :(')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e166b2",
   "metadata": {},
   "source": [
    "7. Find the top 5 most common embarkation ports among passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8105a3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Embarked|count|\n",
      "+--------+-----+\n",
      "|       S|  644|\n",
      "|       C|  168|\n",
      "|       Q|   77|\n",
      "|    NULL|    2|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filled.groupBy('Embarked').count().orderBy(col('count').desc()).show()\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ae94fb",
   "metadata": {},
   "source": [
    "8. Calculate the survival rate by passenger class (Pclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "692ceccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|Pclass|Survival_Rate|\n",
      "+------+-------------+\n",
      "|     1|         0.63|\n",
      "|     3|         0.24|\n",
      "|     2|         0.47|\n",
      "+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, round\n",
    "\n",
    "df_filled.groupBy('Pclass').agg(round(avg('Survived'), 2).alias('Survival_Rate')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39629167",
   "metadata": {},
   "source": [
    "9. Determine the maximum, minimum, and average fare paid by passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aa342f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+--------+\n",
      "|Average_Fare|Max_Fare|Min_Fare|\n",
      "+------------+--------+--------+\n",
      "|        32.2|  512.33|     0.0|\n",
      "+------------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import max, min\n",
    "\n",
    "df_filled.agg(round(avg('Fare'),2).alias('Average_Fare'), round(max('Fare'),2).alias('Max_Fare'), min('Fare').alias('Min_Fare')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6e9151",
   "metadata": {},
   "source": [
    "10. Write a Spark job to count the number of passengers in each age group (e.g., 0–18, 19–35, 36–60, 60+)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a5c9afae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|age_group|count|\n",
      "+---------+-----+\n",
      "|    19-35|  535|\n",
      "|      60+|   22|\n",
      "|    36-60|  195|\n",
      "|     0-18|  139|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "age_groups = df_filled.withColumn(\n",
    "    \"age_group\",\n",
    "    when(col(\"Age\") <= 18, \"0-18\")\n",
    "    .when((col(\"Age\") > 18) & (col(\"Age\") <= 35), \"19-35\")\n",
    "    .when((col(\"Age\") > 35) & (col(\"Age\") <= 60), \"36-60\")\n",
    "    .otherwise(\"60+\")\n",
    ")\n",
    "\n",
    "age_groups.groupBy('age_group').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e851105",
   "metadata": {},
   "source": [
    "11. Create a new directory in HDFS called titanic_lab and list its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f98f36a",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "hdfs dfs -mkdir /titanic_lab\n",
    "hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f396d962",
   "metadata": {},
   "source": [
    "12. Upload the Titanic dataset from your local machine to the titanic_lab directory in HDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1966ed17",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "docker exec namenode hdfs dfs -put /data/titanic.csv /titanic_lab/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04c7da5",
   "metadata": {},
   "source": [
    "\n",
    "13. Use chmod command to change the permissions of the Titanic dataset file to 777 (full permissionsfor all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca73ce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "docker exec namenode hdfs dfs -chmod 777 /titanic_lab/titanic.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3660db52",
   "metadata": {},
   "source": [
    "\n",
    "14. Use-cat to display the first 20 lines of the Titanic dataset stored in HDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a84063",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "docker exec namenode hdfs dfs -cat /titanic_lab/titanic.csv | head -20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c55ae95",
   "metadata": {},
   "source": [
    "15- Move the processed output file from titanic_lab to a new directory in HDFS called titanic_results using hdfs dfs -mv.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b31d51",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "docker exec namenode hdfs dfs -mkdir /titanic_results\n",
    "\n",
    "\n",
    "docker exec namenode hdfs dfs -put /data/titanic_filled.csv /titanic_lab/\n",
    "docker exec namenode hdfs dfs -mv /titanic_lab/titanic_filled.csv /titanic_results/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
