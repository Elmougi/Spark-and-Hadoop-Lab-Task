# Spark-and-Hadoop-Lab-Task


## Overview
This notebook (`task.ipynb`) is a learning exercise in data preprocessing and analysis using **Apache Spark**.  
It is based on the Titanic dataset and is structured as a sequence of numbered tasks (1â€“11, etc.), each focusing on a specific Spark concept.

## Requirements
- Python 3.8+
- Apache Spark with PySpark installed
- HDFS (if saving results to a distributed system; otherwise adapt to local storage)

## Usage
1. Start a Spark environment (local standalone or cluster).
2. Place the Titanic dataset (`titanic.csv`) in the `/data/` directory or update the path in the notebook.
3. Open `task.ipynb` in Jupyter Notebook or JupyterLab.
4. Work through the numbered tasks one by one.
